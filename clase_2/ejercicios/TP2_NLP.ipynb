{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Desafio 2\n",
        "Crear sus propios vectores con Gensim basado en lo visto en clase con otro dataset.\n",
        "\n",
        "Probar términos de interés y explicar similitudes en el espacio de embeddings.\n",
        "\n",
        "Intentar plantear y probar tests de analogías.\n",
        "\n",
        "Graficar los embeddings resultantes.\n",
        "\n",
        "Sacar conclusiones."
      ],
      "metadata": {
        "id": "hsHpKZLxbu_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instala la librería datasets de Hugging Face para acceder a conjuntos de datos."
      ],
      "metadata": {
        "id": "qFKwITagcxWD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx_XAx1_0dm_",
        "outputId": "662b3ff0-5740-4702-e59b-c640c3ae9841"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importa las librerías necesarias para cargar datos, crear modelos de Word2Vec, y visualizar resultados."
      ],
      "metadata": {
        "id": "3bhjZ6L4dIrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from gensim.models import Word2Vec\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import multiprocessing"
      ],
      "metadata": {
        "id": "lXG7CjaK3QSF"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carga el dataset SNLI"
      ],
      "metadata": {
        "id": "szXdEQRL0pQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el dataset GLUE subset sst-2\n",
        "dataset = load_dataset(\"stanfordnlp/snli\")\n",
        "df= pd.DataFrame(dataset['train'])"
      ],
      "metadata": {
        "id": "QO0J6CJi0n8H"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len( df )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpbMCg4u0sfG",
        "outputId": "d746166a-5a74-44ff-a4fb-64dc21492b8c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "550152"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(dataset['train']['premise'], columns=[\"premise\"])\n",
        "df.drop_duplicates(inplace=True)\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YCULUK00uPW",
        "outputId": "d69c6205-b8cf-4ea4-e04c-759c903fdf70"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150736, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocesamiento"
      ],
      "metadata": {
        "id": "4O5EIVQ40x6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "sentence_tokens = []\n",
        "# Recorrer todas las filas y transformar las oraciones\n",
        "# en una secuencia de palabras (esto podría realizarse con NLTK o spaCy también)\n",
        "for _, row in df[:None].iterrows():\n",
        "    sentence_tokens.append(text_to_word_sequence(row[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6SHOlsj0zuI",
        "outputId": "07b2de79-b82b-4317-be27-14f949ca31d8"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-74-99a399a8b871>:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  sentence_tokens.append(text_to_word_sequence(row[0]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Demos un vistazo\n",
        "sentence_tokens[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI_hDfzW0w9U",
        "outputId": "baefd5f7-3235-4eee-fef9-a805ef667a83"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['a',\n",
              "  'person',\n",
              "  'on',\n",
              "  'a',\n",
              "  'horse',\n",
              "  'jumps',\n",
              "  'over',\n",
              "  'a',\n",
              "  'broken',\n",
              "  'down',\n",
              "  'airplane'],\n",
              " ['children', 'smiling', 'and', 'waving', 'at', 'camera']]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Crear los vectores (word2vvc)"
      ],
      "metadata": {
        "id": "Jdp7A4MD05DP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "# Durante el entrenamiento gensim por defecto no informa el \"loss\" en cada época\n",
        "# Sobrecargamos el callback para poder tener esta información\n",
        "class callback(CallbackAny2Vec):\n",
        "    \"\"\"\n",
        "    Callback to print loss after each epoch\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        loss = model.get_latest_training_loss()\n",
        "        if self.epoch == 0:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
        "        else:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
        "        self.epoch += 1\n",
        "        self.loss_previous_step = loss"
      ],
      "metadata": {
        "id": "Q7VtigQe04JH"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crearmos el modelo generador de vectores\n",
        "# En este caso utilizaremos la estructura modelo Skipgram\n",
        "w2v_model = Word2Vec(min_count=5,    # frecuencia mínima de palabra para incluirla en el vocabulario\n",
        "                     window=2,       # cant de palabras antes y desp de la predicha\n",
        "                     vector_size=300,       # dimensionalidad de los vectores\n",
        "                     negative=20,    # cantidad de negative samples... 0 es no se usa\n",
        "                     workers=1,      # si tienen más cores pueden cambiar este valor\n",
        "                     sg=1)"
      ],
      "metadata": {
        "id": "Sle1okm71BJ5"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el vocabulario con los tokens\n",
        "w2v_model.build_vocab(sentence_tokens)"
      ],
      "metadata": {
        "id": "HRvRUewL1CUS"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cantidad de filas/docs encontradas en el corpus\n",
        "print(\"Cantidad de docs en el corpus:\", w2v_model.corpus_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh959E_l1DIU",
        "outputId": "e189ff51-86b1-4d04-c221-057401bab298"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de docs en el corpus: 150736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cantidad de words encontradas en el corpus\n",
        "print(\"Cantidad de words distintas en el corpus:\", len(w2v_model.wv.index_to_key))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up-JiYQ_1FOc",
        "outputId": "a9574869-b669-4597-a56f-604ea62831b1"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de words distintas en el corpus: 7554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento de embeddings"
      ],
      "metadata": {
        "id": "VT161x_M1Hhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo generador de vectores\n",
        "# Utilizamos nuestro callback\n",
        "w2v_model.train(sentence_tokens,\n",
        "                 total_examples=w2v_model.corpus_count,\n",
        "                 epochs=20,\n",
        "                 compute_loss = True,\n",
        "                 callbacks=[callback()]\n",
        "                 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpHnUpqY1Jqp",
        "outputId": "c91602b6-8eb6-4d59-d3be-c95465b6278a"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after epoch 0: 8633490.0\n",
            "Loss after epoch 1: 7168520.0\n",
            "Loss after epoch 2: 6794294.0\n",
            "Loss after epoch 3: 6657308.0\n",
            "Loss after epoch 4: 6606584.0\n",
            "Loss after epoch 5: 6577784.0\n",
            "Loss after epoch 6: 6495608.0\n",
            "Loss after epoch 7: 6438184.0\n",
            "Loss after epoch 8: 6368996.0\n",
            "Loss after epoch 9: 5628488.0\n",
            "Loss after epoch 10: 1693424.0\n",
            "Loss after epoch 11: 1648448.0\n",
            "Loss after epoch 12: 1608728.0\n",
            "Loss after epoch 13: 1571512.0\n",
            "Loss after epoch 14: 1533024.0\n",
            "Loss after epoch 15: 1491136.0\n",
            "Loss after epoch 16: 1458920.0\n",
            "Loss after epoch 17: 1415912.0\n",
            "Loss after epoch 18: 1381640.0\n",
            "Loss after epoch 19: 1352392.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23081213, 36931460)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensayar\n",
        "### Prueba de analogias"
      ],
      "metadata": {
        "id": "lKYf4BE51SSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "print(w2v_model.wv.most_similar(positive=['horse', 'jump'], negative=['person'], topn=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwxHh2iV1TWx",
        "outputId": "4a895059-6dd4-46b4-c4bd-e799c9604d8d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('leap', 0.38963237404823303), ('horseback', 0.37196215987205505), ('horses', 0.3712778389453888), ('hurdle', 0.3706740140914917), ('stride', 0.36630383133888245)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encuentra las palabras que están contextualmente más relacionadas con 'horse' y 'jump' al quitar 'person'. Esto refleja cómo el modelo entiende las asociaciones semánticas basadas en el corpus."
      ],
      "metadata": {
        "id": "1TVY4_erf_SE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(w2v_model.wv.most_similar(positive=['smiling', 'camera'], negative=['crazy'], topn=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iW0efBUq1amx",
        "outputId": "7742f6e9-61ca-4345-e0d5-4fd26edf8931"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('smiles', 0.4003285765647888), ('caring', 0.35034629702568054), ('camcorder', 0.34751465916633606), ('gesticulates', 0.33764874935150146), ('takeout', 0.33502835035324097)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo muestra las palabras más relacionadas con 'smiling' y 'camera' excluyendo 'crazy', lo que proporciona una visión de las similitudes de contexto."
      ],
      "metadata": {
        "id": "lFRNGZhyf9Fr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensayar"
      ],
      "metadata": {
        "id": "e8LvS57S1iih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(positive=[\"peruse\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lAsPiQh1rHg",
        "outputId": "f68cc352-8d13-4312-b9b2-242097c14bdc"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('browse', 0.7479051947593689),\n",
              " ('flee', 0.728155791759491),\n",
              " (\"farmer's\", 0.7123233079910278),\n",
              " ('available', 0.7020047307014465),\n",
              " ('flea', 0.6824276447296143),\n",
              " ('spices', 0.6749407052993774),\n",
              " ('lettuce', 0.6705610752105713),\n",
              " ('selecting', 0.6682788729667664),\n",
              " ('browsing', 0.6592974662780762),\n",
              " ('seller', 0.652169942855835)]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Muestra las palabras que tienen una relación más fuerte con 'peruse' según el modelo entrenado."
      ],
      "metadata": {
        "id": "B4Gc4q-Xf4oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MENOS se relacionan con...:\n",
        "w2v_model.wv.most_similar(negative=[\"horse\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nDZC5Gi1rt3",
        "outputId": "2e0de4b3-e2a4-4527-f42d-8d78e4c871da"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('use', 0.04635145887732506),\n",
              " ('measuring', 0.04579503461718559),\n",
              " ('serving', 0.015008862130343914),\n",
              " ('reviewing', 0.014689343981444836),\n",
              " ('multiple', 0.01393023319542408),\n",
              " ('washing', 0.002902029547840357),\n",
              " ('temple', 0.0004069445712957531),\n",
              " ('dim', -0.0005985419265925884),\n",
              " ('robes', -0.0025097825564444065),\n",
              " ('glass', -0.0067339385859668255)]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encuentra las palabras que están menos relacionadas con 'horse'. Esto puede ayudar a identificar palabras en un contexto opuesto."
      ],
      "metadata": {
        "id": "chG21iZQgC-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(positive=[\"camera\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_Ws1TDW1tnQ",
        "outputId": "9d053743-c53d-458a-e969-710b00e913e5"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('camcorder', 0.524447500705719),\n",
              " ('broadly', 0.49047237634658813),\n",
              " ('viewer', 0.4794682562351227),\n",
              " ('sights', 0.4606354534626007),\n",
              " ('pensive', 0.45903900265693665),\n",
              " (\"camera's\", 0.45532867312431335),\n",
              " ('voice', 0.4451206624507904),\n",
              " ('michael', 0.4411706030368805),\n",
              " ('booklet', 0.4377310574054718),\n",
              " ('curiously', 0.434591680765152)]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Muestra las palabras más cercanas en contexto a 'camera'."
      ],
      "metadata": {
        "id": "HataXnZzgEVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MENOS se relacionan con...:\n",
        "w2v_model.wv.most_similar(negative=[\"smiling\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flynN-fS1ufW",
        "outputId": "7d0e9ef1-6586-4b51-e600-3a111a27f731"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cinder', 0.017938319593667984),\n",
              " ('dry', 0.016183335334062576),\n",
              " ('glider', 0.012503043748438358),\n",
              " ('way', 0.009737120941281319),\n",
              " ('biker', 0.009433901868760586),\n",
              " ('form', 0.00879032164812088),\n",
              " ('series', 0.0028385629411786795),\n",
              " ('jets', -0.0006394082447513938),\n",
              " ('complete', -0.0019747684709727764),\n",
              " ('engaged', -0.003408650867640972)]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encuentra palabras menos asociadas a 'smiling' en el espacio de embeddings."
      ],
      "metadata": {
        "id": "IvnfAxJCgHBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensayar con una palabra que no está en el vocabulario:\n",
        "w2v_model.wv.most_similar(negative=[\"personitas\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "txCUYdd41wU1",
        "outputId": "927c87fd-7bcc-43d2-dc8d-e20d3e17032d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"Key 'personitas' not present in vocabulary\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-c621a9366db2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Ensayar con una palabra que no está en el vocabulario:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"personitas\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0;31m# compute the weighted average of all keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mean_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         all_keys = [\n\u001b[1;32m    843\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_index_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_mean_vector\u001b[0;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mtotal_weight\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present in vocabulary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_weight\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Key 'personitas' not present in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intenta encontrar palabras similares usando una palabra fuera del vocabulario, lo que puede generar errores o resultados vacíos."
      ],
      "metadata": {
        "id": "-WJBTnaogJNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# el método `get_vector` permite obtener los vectores:\n",
        "vector_love = w2v_model.wv.get_vector(\"smiling\")\n",
        "print(vector_love)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3LG1b371yhV",
        "outputId": "4fbfb915-8e51-49c9-ec7b-541bc2f929a0"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.19463693 -0.13363379  0.24833597 -0.25546852 -0.34012341 -0.49376348\n",
            " -0.21987657  0.7508575  -0.2017214  -0.01726481  0.33083588 -0.15334775\n",
            " -0.21345696  0.29398057 -0.25296152  0.35275754 -0.17929032  0.07357505\n",
            " -0.09261425  0.09505588  0.33308882 -0.17235437  0.0936766  -0.01048534\n",
            "  0.2313013  -0.49826455 -0.01240153 -0.2335476   0.1644789  -0.26676977\n",
            " -0.49975023  0.13829052 -0.01153416 -0.17409554  0.02811989  0.34137484\n",
            "  0.4274253  -0.05360426 -0.18282875  0.11406602 -0.21219207 -0.14062618\n",
            "  0.23529898  0.32691878  0.6096664  -0.16201793 -0.21921638  0.15018469\n",
            " -0.12900235  0.27311724 -0.37904975 -0.17950614  0.44004977 -0.11958599\n",
            "  0.08537972  0.26369038 -0.107324    0.00852096  0.1071149   0.2188916\n",
            "  0.10096107  0.27153903  0.10569486  0.4192863  -0.12116634  0.46034393\n",
            " -0.31794244 -0.06429811 -0.3341793  -0.10204653 -0.08209068  0.16445595\n",
            " -0.09221222 -0.11624147  0.17034437  0.03856412 -0.04710691 -0.08040558\n",
            " -0.64567465  0.08753073  0.08150253 -0.33568144  0.35444674  0.05486353\n",
            "  0.16095984 -0.31105027  0.15029109 -0.09218118  0.33004746  0.06414101\n",
            "  0.05719702  0.30526683  0.03427893  0.18025883  0.40895164  0.46766573\n",
            "  0.2794644   0.12568966 -0.07108002 -0.11647433 -0.2957703   0.2306972\n",
            "  0.08495568  0.17733969 -0.19369501  0.00127629  0.11945952  0.36324263\n",
            " -0.20365942  0.03842629  0.22570294  0.2567729  -0.36814377 -0.4007418\n",
            " -0.23787276  0.18889949  0.0140475   0.21007174 -0.2694159   0.0488465\n",
            "  0.02447671  0.26518512 -0.52100885 -0.06545953 -0.10686974  0.29056853\n",
            " -0.30513096 -0.03446032 -0.3977749   0.32045603  0.43019387 -0.17799458\n",
            "  0.3124793  -0.2973421   0.33346117  0.1258921   0.21743545 -0.451136\n",
            "  0.15012349 -0.10495909 -0.18633242 -0.17428058 -0.20197335 -0.3410821\n",
            "  0.1053682  -0.0099694   0.23867245  0.11240026 -0.08106092 -0.09094044\n",
            "  0.00604625 -0.22001593 -0.07301573  0.08586689 -0.02620207 -0.256902\n",
            " -0.05961541 -0.23843022  0.00714743  0.5676147  -0.37896308 -0.06312929\n",
            "  0.011312   -0.23792984 -0.04789207 -0.07902343  0.13579594  0.19632244\n",
            "  0.36223716  0.18250111 -0.24224515 -0.12325289 -0.00157128 -0.05403036\n",
            " -0.28980848 -0.21583652 -0.0203679   0.1096877   0.16848586 -0.6809163\n",
            " -0.1832314   0.17662403 -0.02122976  0.07465701  0.10694306 -0.14158183\n",
            "  0.7537442   0.269698    0.16009627 -0.04878144 -0.15985736  0.24800903\n",
            " -0.28976315 -0.05593269 -0.15003417 -0.32123044 -0.1346821  -0.17495532\n",
            "  0.13627861  0.12493843 -0.00798429 -0.46132872  0.0250397  -0.18149044\n",
            " -0.00258177  0.3316169  -0.04643653 -0.49940258 -0.12101756  0.13396338\n",
            " -0.27610698 -0.15711072  0.31523535 -0.04533213 -0.22229801 -0.16643003\n",
            "  0.05819978 -0.03215114 -0.12523432 -0.10576724 -0.00943199  0.46069148\n",
            "  0.1298797  -0.6460015  -0.10684899 -0.19935097  0.27805492 -0.32007995\n",
            " -0.07993598  0.2246241   0.4509641  -0.13842107  0.3964607  -0.2800241\n",
            "  0.10206972  0.06024071 -0.30756173 -0.10275737  0.09736864  0.19674116\n",
            "  0.1232141  -0.01232479  0.22290382  0.49953967  0.37418517 -0.20153959\n",
            " -0.30164665 -0.21992907 -0.0531557  -0.36481607 -0.20302661 -0.1029143\n",
            "  0.3362415  -0.23229295 -0.32823086 -0.05377948  0.19731137  0.10376307\n",
            " -0.16146083  0.02853581  0.47571245 -0.26696134  0.68140596 -0.3805502\n",
            " -0.13785025 -0.02460646 -0.12951918  0.15122719 -0.40519023 -0.28232047\n",
            " -0.22441046  0.2543111   0.21359406 -0.2293953   0.16243082  0.3318906\n",
            " -0.02526314  0.16323385 -0.70907235  0.06975155 -0.00727588  0.07537599\n",
            " -0.4870893   0.2463959  -0.12810557  0.38343453  0.20655473 -0.04975223\n",
            "  0.07808533  0.12285447  0.33255395 -0.05427143  0.11614184 -0.09827137\n",
            "  0.10908286 -0.06867518 -0.3854217  -0.29205456  0.44308025  0.0202354 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extrae el vector asociado a la palabra 'smiling', lo que permite ver su representación numérica."
      ],
      "metadata": {
        "id": "CPg7LmaCgMaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# el método `most_similar` también permite comparar a partir de vectores\n",
        "w2v_model.wv.most_similar(vector_love)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jypBvo0g10JR",
        "outputId": "08c68298-4462-4d3e-b77b-5fed25b79097"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('smiling', 1.0),\n",
              " ('smiles', 0.5130669474601746),\n",
              " ('laughing', 0.47333085536956787),\n",
              " ('yawns', 0.44452354311943054),\n",
              " ('giggling', 0.4311577379703522),\n",
              " ('grins', 0.42983126640319824),\n",
              " ('ladle', 0.41926735639572144),\n",
              " ('grinning', 0.40386784076690674),\n",
              " ('frowning', 0.4018012285232544),\n",
              " ('gesticulates', 0.39961856603622437)]"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encuentra palabras similares usando un vector en lugar de una palabra, mostrando la flexibilidad del método."
      ],
      "metadata": {
        "id": "guGkFkoNgN8o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizacion de agrupacion de vectores"
      ],
      "metadata": {
        "id": "c799xP9111-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "\n",
        "def reduce_dimensions(model, num_dimensions = 2 ):\n",
        "\n",
        "    vectors = np.asarray(model.wv.vectors)\n",
        "    labels = np.asarray(model.wv.index_to_key)\n",
        "\n",
        "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
        "    vectors = tsne.fit_transform(vectors)\n",
        "\n",
        "    return vectors, labels"
      ],
      "metadata": {
        "id": "epLYlcng15Wp"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar los embedddings en 2D\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "vecs, labels = reduce_dimensions(w2v_model)\n",
        "\n",
        "MAX_WORDS=200\n",
        "fig = px.scatter(x=vecs[:MAX_WORDS,0], y=vecs[:MAX_WORDS,1], text=labels[:MAX_WORDS])\n",
        "fig.show(renderer=\"colab\") # esto para plotly en colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "LBv_PuVV19__",
        "outputId": "a1a78ad9-7da7-45d0-b0c5-79ca416a25d0"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"e9fe731f-244f-42e1-b092-7f830cbf1967\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e9fe731f-244f-42e1-b092-7f830cbf1967\")) {                    Plotly.newPlot(                        \"e9fe731f-244f-42e1-b092-7f830cbf1967\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"a\",\"in\",\"the\",\"on\",\"and\",\"man\",\"is\",\"of\",\"with\",\"woman\",\"two\",\"are\",\"to\",\"people\",\"at\",\"an\",\"wearing\",\"shirt\",\"white\",\"young\",\"black\",\"while\",\"his\",\"blue\",\"red\",\"girl\",\"sitting\",\"men\",\"boy\",\"standing\",\"dog\",\"playing\",\"street\",\"group\",\"down\",\"front\",\"her\",\"walking\",\"holding\",\"one\",\"water\",\"three\",\"by\",\"green\",\"up\",\"women\",\"looking\",\"child\",\"as\",\"for\",\"little\",\"large\",\"outside\",\"brown\",\"yellow\",\"person\",\"children\",\"through\",\"hat\",\"their\",\"from\",\"other\",\"ball\",\"small\",\"next\",\"over\",\"into\",\"some\",\"dressed\",\"out\",\"running\",\"building\",\"riding\",\"jacket\",\"another\",\"around\",\"orange\",\"near\",\"field\",\"stands\",\"crowd\",\"beach\",\"pink\",\"background\",\"sidewalk\",\"behind\",\"hair\",\"jumping\",\"table\",\"girls\",\"sits\",\"snow\",\"grass\",\"bike\",\"looks\",\"top\",\"camera\",\"that\",\"asian\",\"air\",\"city\",\"stand\",\"dogs\",\"wall\",\"older\",\"player\",\"off\",\"four\",\"has\",\"working\",\"gray\",\"soccer\",\"blond\",\"dress\",\"something\",\"several\",\"talking\",\"park\",\"shorts\",\"lady\",\"it\",\"guitar\",\"picture\",\"boys\",\"him\",\"walks\",\"hand\",\"pants\",\"smiling\",\"plays\",\"jeans\",\"along\",\"play\",\"dark\",\"game\",\"road\",\"carrying\",\"holds\",\"together\",\"bench\",\"food\",\"car\",\"walk\",\"them\",\"side\",\"long\",\"baby\",\"face\",\"there\",\"head\",\"old\",\"glasses\",\"sit\",\"stage\",\"back\",\"bicycle\",\"hands\",\"tree\",\"taking\",\"doing\",\"rock\",\"pool\",\"watching\",\"t\",\"couple\",\"guy\",\"each\",\"male\",\"area\",\"baseball\",\"ground\",\"dirt\",\"who\",\"female\",\"he\",\"being\",\"boat\",\"day\",\"race\",\"middle\",\"striped\",\"jumps\",\"performing\",\"construction\",\"look\",\"mouth\",\"many\",\"coat\",\"suit\",\"across\",\"room\",\"purple\",\"sunglasses\",\"eating\",\"football\",\"sign\",\"horse\",\"under\",\"band\",\"kids\"],\"x\":[11.185006,4.269638,-35.93953,-8.86649,10.64035,9.86513,10.759086,-4.215577,11.451827,-4.8624935,-3.702011,13.984632,-23.342144,-4.088144,-24.188559,20.516724,-0.0037137265,8.682281,16.372015,-2.9712338,15.717548,-1.2757934,-0.21353163,9.435468,11.1869545,-0.39220265,27.211464,-4.669134,-6.062798,22.097149,35.279892,-30.885782,11.698676,-39.18899,11.786896,-7.157843,-0.48510733,26.124031,14.550963,-1.9103392,27.949747,-4.3139634,6.1673336,8.2888775,3.1400182,-16.593853,25.796461,-6.3167014,-26.760746,-9.15271,-2.809307,-14.538877,0.7381172,32.283222,13.255794,10.036165,-3.6621478,15.096666,8.43419,-24.372105,-22.656496,-10.669,-19.63805,18.741674,15.712762,-8.633489,-17.682123,-1.8358052,-3.9051363,-4.8479548,37.14055,-11.680795,22.885496,12.311569,-27.876839,17.938822,13.285152,-7.9690304,18.837471,22.003784,-41.054916,27.44187,4.9038253,12.058732,11.530934,-17.663752,4.023304,33.414425,-2.7632232,-4.001587,26.898056,-33.000343,18.014334,26.226131,25.412888,5.0484633,8.452606,-22.376568,-6.312989,-15.729914,10.183966,2.950785,37.459713,-12.661136,-5.839676,-17.784191,-22.284185,-4.2128596,15.261705,21.911242,6.450635,-12.288266,0.14353663,4.2763076,-3.3754926,-4.925287,23.037596,9.185756,9.902075,-4.854307,-30.00223,-36.872997,-19.5467,21.5681,-26.533865,26.289305,4.230408,9.492792,18.125355,20.647638,10.077953,12.403308,-30.926805,15.922438,-7.9146686,14.892059,17.844234,14.456112,3.6879814,-4.268145,11.820203,-3.023588,14.148426,-7.95831,-21.47388,5.5842896,-5.7834754,4.1190796,29.025333,3.727235,-5.7497215,6.099641,27.526592,-36.11221,-22.271582,26.23867,-26.192657,15.326241,19.706161,44.86294,-12.747225,29.53211,31.508451,10.664473,1.8058687,10.108517,29.440928,20.552149,15.034143,-15.783304,-8.059771,17.086102,21.209013,18.793318,-34.684166,8.175659,30.426931,8.454945,-1.0281401,-34.98367,10.437021,33.32637,-33.8949,22.93789,28.41764,-8.913246,-0.8608766,12.366447,10.358946,14.837753,-28.52269,4.4620748,6.1773133,11.0792675,-16.661129,-18.319948,39.104694,-20.07838,-37.06624,-3.5794957],\"xaxis\":\"x\",\"y\":[-33.114365,-38.74092,-3.1274788,-14.161478,-36.0017,-31.968014,-30.848042,6.98485,-31.443476,-32.089733,46.71846,-11.940085,32.521873,29.053816,-30.057304,-20.11692,-40.037834,-39.058937,-36.52555,-33.659927,-36.549862,-19.191942,-22.261032,-35.895718,-36.2898,-35.284885,-24.956629,29.132797,-29.25751,-28.874643,-22.065908,3.0483534,23.213821,10.060965,25.078188,1.727823,-22.92696,33.142715,-23.782022,-24.344189,40.63171,46.439445,21.929619,-46.939365,-6.3928056,-45.23591,-32.082634,-28.606834,-11.605918,21.986765,-33.41004,-8.561354,19.051832,-22.583315,-38.323074,-31.950548,30.499155,19.795586,-33.942158,4.0132837,-6.275928,29.12529,41.43418,-20.82329,-10.699618,-24.724415,-10.351296,4.9974637,-39.32301,1.9676812,-18.30441,1.9759442,31.636517,-37.0254,-25.854286,16.466066,-43.324257,0.48394242,19.320362,-28.967726,15.649115,20.625645,-43.447372,20.60342,23.14116,-2.6021037,-31.274668,25.112434,8.277279,-30.509256,-25.08917,-29.30625,18.456903,37.120872,-32.73448,-38.105907,-16.48327,16.21562,-37.05797,-15.16091,27.44855,25.703379,-21.163061,1.0932565,-34.954647,39.77074,31.278795,46.503025,-21.795795,-3.9704015,-33.9773,36.232574,-31.808697,-39.362564,18.123417,47.78716,-25.370071,20.92504,-41.670406,-32.115246,26.557545,2.6107483,6.4726954,-46.853855,32.614044,33.63287,-21.896828,-41.72778,-21.922325,-34.15869,-39.71155,24.86273,3.2063956,-38.16409,36.949726,23.153624,-16.29551,-23.60626,22.085064,-13.127427,7.530981,-7.327131,36.34227,5.9154134,-0.3992502,-32.89388,-27.180698,-20.973623,8.47911,-20.585531,-34.15195,-33.304054,-24.862572,9.364945,-1.3188553,37.1233,-16.65442,14.601457,-17.657804,0.5668188,-8.393184,20.483767,-11.297,-39.48152,21.536884,-31.656858,-16.104404,-21.213116,31.96479,42.767487,-12.659831,25.904623,-19.498363,-48.88036,-7.5469856,41.687984,16.734804,32.412186,36.341965,-20.784182,-39.22929,25.156803,13.376001,-2.728339,5.4898415,-23.546175,26.136703,-37.039387,-36.817055,27.655664,3.7423406,-43.91968,-33.976734,10.191944,40.161964,11.8149185,-9.796984,-1.3403147,8.390381,30.664116],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e9fe731f-244f-42e1-b092-7f830cbf1967');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# También se pueden guardar los vectores y labels como tsv para graficar en\n",
        "# http://projector.tensorflow.org/\n",
        "\n",
        "\n",
        "vectors = np.asarray(w2v_model.wv.vectors)\n",
        "labels = list(w2v_model.wv.index_to_key)\n",
        "\n",
        "np.savetxt(\"vectors.tsv\", vectors, delimiter=\"\\t\")\n",
        "\n",
        "with open(\"labels.tsv\", \"w\") as fp:\n",
        "    for item in labels:\n",
        "        fp.write(\"%s\\n\" % item)"
      ],
      "metadata": {
        "id": "EZbftd4c2F_M"
      },
      "execution_count": 93,
      "outputs": []
    }
  ]
}